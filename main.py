#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""11755_projct_midterm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18vb8MVpOw-Z-RCImYSFlLC2Z6pSq-qtJ
"""

import librosa
import matplotlib.pyplot as plt
import soundfile as sf
import numpy as np
import math
import os
import sklearn.decomposition

"""# Audio Utilities
Audio Utilities: Load Audio and Save audio according to the corresponding feature. \\
TODO: Try other feature extraction methods
"""

HOP_LENGTH = 352
WIN_LENGTH = 1411
n_fft = 2048
n_mels = 128
n_mfcc = 40


def load_audio(filename, max_len=5000):
    # If mfcc already loaded, directly fetch mfcc
    try:
        data = np.load(filename.replace(".wav", ".npz"))
        if max_len == -1:
            return data['M'], data['phase'], data['sr']
        else:
            return data['M'][:, :max_len], data['phase'][:, :max_len], data['sr']
    except:
        pass
    audio, sr = librosa.load(filename, sr=None)

    # mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mels=n_mels, n_mfcc=n_mfcc, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)

    spec = librosa.stft(audio, n_fft=n_fft, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)
    M = np.abs(spec)
    phase = spec / (M + 1e-8)

    # Save spectrum
    np.savez(filename.replace(".wav", ".npz"), M=M, phase=phase, sr=sr)

    if max_len == -1:
        return M, phase, sr
    else:
        return M[:, :max_len], phase[:, :max_len], sr

def save_audio(file_path, M, phase, sr):
    # Convert back to audio
    spec = M * phase
    audio = librosa.istft(spec, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)
    sf.write(file_path, audio, sr)
    print("Audio saved to: ", file_path)

    return audio

"""# NMF
NMF Train Function and definition of KL divergence used in NMF training. \\
TODO: short-time NMF? Change divergence criteria?
"""

def KL_divergence(M, BW):
    eps = 1e-8
    return np.sum(np.multiply(M, np.log(M / BW)) - M + BW)

def NMF_train(M, B_init, W_init, n_iter):
    W = W_init
    B = B_init
    div = []
    eps = 1e-8

    for i in range(n_iter):
        W = np.multiply(W, (B.T @ (M / (B @ W + eps))) / (B.T @ np.ones((M.shape[0], M.shape[1])) + eps))
        B = np.multiply(B, ((M / (B @ W + eps)) @ W.T) / (np.ones((M.shape[0], M.shape[1])) @ W.T + eps))
        if i % 50 == 0:
            print("Iteration: ", i, " L2 divergence: ", np.linalg.norm(M - B @ W))
            div.append(np.linalg.norm(M - B @ W))

    return W, B, div

"""Apply NMF to audio"""

def NMF_apply(M, B_s, B_m, n_iter):
    # B_s - Basis learnt from the vocal component
    # B_m - Basis learnt from the musical component
    B = np.concatenate((B_s, B_m), axis=1)
    W = np.random.rand(B.shape[1], M.shape[1])

    for i in range(n_iter):
        W = np.multiply(W, (B.T @ (M / (B @ W))) / (B.T @ np.ones((M.shape[0], M.shape[1]))))
        if i % 50 == 0:
            print("Separation Iteration: ", i)

    W_s = W[:B_s.shape[1], :]
    W_m = W[B_s.shape[1]:, :]

    M_s = B_s @ W_s
    M_m = B_m @ W_m

    return M_s, M_m
"""# Support Functions"""

def save_bases(B_m, B_s, filename):
    np.savez(filename, B_m=B_m, B_s=B_s)

def load_bases(filename):
    data = np.load(filename)
    return data['B_m'], data['B_s']

"""# Actual Work"""

n_bases_music = 200
n_bases_vocal = 36
train_window = None

def train(music, vocal, n_iter):
    # Load Audio for all audio files in music and vocal folder


    M_music = np.ndarray((1025, 0))
    M_vocal = np.ndarray((1025, 0))

    for music_file in os.listdir(music):
        if not music_file.endswith(".mp3") and not music_file.endswith(".wav"):
            continue
        M, _, _ = load_audio(os.path.join(music, music_file), train_window)
        M_music = np.concatenate((M_music, M), axis=1)
        break
    
    for vocal_file in os.listdir(vocal):
        if not vocal_file.endswith(".mp3") and not vocal_file.endswith(".wav"):
            continue
        M, _, _ = load_audio(os.path.join(vocal, vocal_file), train_window)
        M_vocal = np.concatenate((M_vocal, M), axis=1)
        break

    print("Music shape: ", M_music.shape)
    print("Vocal shape: ", M_vocal.shape)

    B_m = np.random.rand(M_music.shape[0], n_bases_music)
    B_s = np.random.rand(M_vocal.shape[0], n_bases_vocal)
    W_m = np.random.rand(B_m.shape[1], M_music.shape[1])
    W_s = np.random.rand(B_s.shape[1], M_vocal.shape[1])

    # Ensure Numerical Stability
    B_m = np.maximum(B_m, 1e-10)
    B_s = np.maximum(B_s, 1e-10)
    W_m = np.maximum(W_m, 1e-10)
    W_s = np.maximum(W_s, 1e-10)

    W_m, B_m, div_m = NMF_train(M_music, B_m, W_m, n_iter)
    W_s, B_s, div_s = NMF_train(M_vocal, B_s, W_s, n_iter)

    # Sanity Check: What did we learn for vocal?
    # 1. Reconstruct the vocal component using only the first 10 basis

    M_s = B_s[:, :10] @ W_s[:10, :]
    save_audio("vocal_recon.wav", M_s, _, 22050)

    # Use sklearn NMF
    # model_m = sklearn.decomposition.NMF(n_components=n_bases, init='random', max_iter=n_iter, verbose=True, tol=1e-3, alpha_W=0.1, alpha_H=0.1, l1_ratio=0.5)
    # W_m = model_m.fit_transform(M_music.T).T
    # B_m = model_m.components_.T
    # model_s = sklearn.decomposition.NMF(n_components=n_bases, init='random', max_iter=n_iter, verbose=True, tol=1e-3, alpha_W=0.1, alpha_H=0.1, l1_ratio=0.5)
    # W_s = model_s.fit_transform(M_vocal.T).T
    # B_s = model_s.components_.T

    print("Music Basis: ", B_m.shape)
    print("Vocal Basis: ", B_s.shape)


    save_bases(B_m, B_s, "bases.npz")

    return B_m, B_s

def apply(music, n_iter):
    B_m, B_s = load_bases("bases.npz")

    M_music, phase_music, sr = load_audio(music, None)

    M_s, M_m = NMF_apply(M_music, B_s, B_m, n_iter)

    save_audio("vocal.wav", M_s, phase_music, sr)
    save_audio("music.wav", M_m, phase_music, sr)

    return M_s, M_m

"""# Process"""


if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print("Usage: python main.py <train/run> <music>")
        sys.exit(1)
    
    if sys.argv[1] == 'train':
        train_music = "./data/music"
        train_vocal = "./data/vocal"
        B_m, B_s = train(train_music, train_vocal, 1000)
    elif sys.argv[1] == 'run':
        test_music = sys.argv[2]
        apply(test_music, 1000)
    elif sys.argv[1] == 'clean':
        train_music = "./data/music"
        train_vocal = "./data/vocal"
        for file in os.listdir(train_music):
            if file.endswith(".npz"):
                os.remove(os.path.join(train_music, file))
        for file in os.listdir(train_vocal):
            if file.endswith(".npz"):
                os.remove(os.path.join(train_vocal, file))